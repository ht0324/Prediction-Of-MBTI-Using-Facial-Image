{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    enfj\n",
       "1    enfj\n",
       "2    enfj\n",
       "3    enfj\n",
       "4    enfj\n",
       "Name: MBTI, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbti_df = pd.read_csv('crop128/all.csv')\n",
    "\n",
    "photo_df = pd.DataFrame(columns=['photo'], dtype= 'object')\n",
    "\n",
    "# put the photo data into a dataframe\n",
    "for i in range(len(mbti_df)):\n",
    "    image = transform(Image.open('crop128/' + mbti_df['file_name'][i]))\n",
    "    photo_df.loc[i] = [image]\n",
    "\n",
    "mbti_df = mbti_df['MBTI']\n",
    "\n",
    "mbti_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 128])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "photo_df.iloc[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: MBTI, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabet = ['t', 'f']\n",
    "\n",
    "# if mbti_df['MBTI'] includes alphabet[0], then mbti_df['MBTI'] = 1, else 0\n",
    "mbti_df = mbti_df.apply(lambda x: 1 if alphabet[0] in x else 0)\n",
    "\n",
    "mbti_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    1315\n",
      "0    1233\n",
      "Name: MBTI, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#print the statistics of the mbti_df\n",
    "print(mbti_df.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data includes the element of 2-dim tensor\n",
    "train_data = photo_df['photo'].values\n",
    "train_label = mbti_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#전체 data 중 train의 비율\n",
    "train_ratio = 0.8\n",
    "\n",
    "train_idx = np.random.choice(len(train_data), int(len(train_data) * train_ratio), replace=False)\n",
    "test_idx = np.array(list(set(range(len(train_data))) - set(train_idx)))\n",
    "\n",
    "test_data = train_data[test_idx]\n",
    "test_label = train_label[test_idx]\n",
    "\n",
    "train_data = train_data[train_idx]\n",
    "train_label = train_label[train_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from math import floor\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.layers import LeakyReLU\n",
    "import keras\n",
    "LeakyReLU = LeakyReLU(alpha=0.1)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "score_acc = make_scorer(accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimizer for cnn image classification\n",
    "def nn_cl_bo(neurons, activation, optimizer, learning_rate,  batch_size, epochs ):\n",
    "    # Create model\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=(1, 32, 32)))\n",
    "    model.add(keras.layers.Dense(neurons))\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=optimizer(lr=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    # Fit the model\n",
    "    model.fit(train_data, train_label, batch_size=batch_size, epochs=epochs, verbose=0)\n",
    "    # Evaluate the model\n",
    "    scores = model.evaluate(test_data, test_label, verbose=0)\n",
    "    return scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | activa... | batch_... |  epochs   | learni... |  neurons  | optimizer |\n",
      "-------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39m# Run Bayesian Optimization\u001b[39;00m\n\u001b[1;32m     11\u001b[0m nn_bo \u001b[39m=\u001b[39m BayesianOptimization(nn_cl_bo, params_nn, random_state\u001b[39m=\u001b[39m\u001b[39m123\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m nn_bo\u001b[39m.\u001b[39;49mmaximize(init_points\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, n_iter\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n\u001b[1;32m     14\u001b[0m \u001b[39mprint\u001b[39m(nn_bo\u001b[39m.\u001b[39mmax)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/bayes_opt/bayesian_optimization.py:311\u001b[0m, in \u001b[0;36mBayesianOptimization.maximize\u001b[0;34m(self, init_points, n_iter, acquisition_function, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    309\u001b[0m     x_probe \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msuggest(util)\n\u001b[1;32m    310\u001b[0m     iteration \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 311\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprobe(x_probe, lazy\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    313\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bounds_transformer \u001b[39mand\u001b[39;00m iteration \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    314\u001b[0m     \u001b[39m# The bounds transformer should only modify the bounds after\u001b[39;00m\n\u001b[1;32m    315\u001b[0m     \u001b[39m# the init_points points (only for the true iterations)\u001b[39;00m\n\u001b[1;32m    316\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_bounds(\n\u001b[1;32m    317\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bounds_transformer\u001b[39m.\u001b[39mtransform(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_space))\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/bayes_opt/bayesian_optimization.py:208\u001b[0m, in \u001b[0;36mBayesianOptimization.probe\u001b[0;34m(self, params, lazy)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_queue\u001b[39m.\u001b[39madd(params)\n\u001b[1;32m    207\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 208\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_space\u001b[39m.\u001b[39;49mprobe(params)\n\u001b[1;32m    209\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch(Events\u001b[39m.\u001b[39mOPTIMIZATION_STEP)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/bayes_opt/target_space.py:236\u001b[0m, in \u001b[0;36mTargetSpace.probe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    234\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_as_array(params)\n\u001b[1;32m    235\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_keys, x))\n\u001b[0;32m--> 236\u001b[0m target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m    238\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constraint \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    239\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mregister(x, target)\n",
      "Cell \u001b[0;32mIn [12], line 8\u001b[0m, in \u001b[0;36mnn_cl_bo\u001b[0;34m(neurons, activation, optimizer, learning_rate, batch_size, epochs)\u001b[0m\n\u001b[1;32m      6\u001b[0m model\u001b[39m.\u001b[39madd(keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(neurons))\n\u001b[1;32m      7\u001b[0m model\u001b[39m.\u001b[39madd(keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m1\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msigmoid\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m----> 8\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39moptimizer(lr\u001b[39m=\u001b[39;49mlearning_rate), loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      9\u001b[0m \u001b[39m# Fit the model\u001b[39;00m\n\u001b[1;32m     10\u001b[0m model\u001b[39m.\u001b[39mfit(train_data, train_label, batch_size\u001b[39m=\u001b[39mbatch_size, epochs\u001b[39m=\u001b[39mepochs, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not callable"
     ]
    }
   ],
   "source": [
    "# Set paramaters\n",
    "params_nn ={\n",
    "    'neurons': (10, 100),\n",
    "    'activation':(0, 9),\n",
    "    'optimizer':(0,7),\n",
    "    'learning_rate':(0.01, 1),\n",
    "    'batch_size':(200, 1000),\n",
    "    'epochs':(20, 100)\n",
    "}\n",
    "# Run Bayesian Optimization\n",
    "nn_bo = BayesianOptimization(nn_cl_bo, params_nn, random_state=123)\n",
    "nn_bo.maximize(init_points=5, n_iter=10)\n",
    "\n",
    "print(nn_bo.max)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bb56f16a476da825ad38aece63bf2b6f81498eae50365174bfcab711b333a091"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
