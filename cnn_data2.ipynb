{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    enfj\n",
       "1    enfj\n",
       "2    enfj\n",
       "3    enfj\n",
       "4    enfj\n",
       "Name: MBTI, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbti_df = pd.read_csv('crop128/all.csv')\n",
    "\n",
    "photo_df = pd.DataFrame(columns=['photo'], dtype= 'object')\n",
    "\n",
    "# put the photo data into a dataframe\n",
    "for i in range(len(mbti_df)):\n",
    "    image = transform(Image.open('crop128/' + mbti_df['filename'][i]))\n",
    "    photo_df.loc[i] = [image]\n",
    "\n",
    "mbti_df = mbti_df['MBTI']\n",
    "\n",
    "mbti_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 64])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "photo_df.iloc[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: MBTI, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabet = ['t', 'f']\n",
    "\n",
    "# if mbti_df['MBTI'] includes alphabet[0], then mbti_df['MBTI'] = 0, else 1\n",
    "mbti_df = mbti_df.apply(lambda x: 1 if alphabet[0] in x else 0)\n",
    "\n",
    "mbti_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    1551\n",
      "0    1493\n",
      "Name: MBTI, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#print the statistics of the mbti_df\n",
    "print(mbti_df.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data includes the element of 2-dim tensor\n",
    "train_data = photo_df['photo'].values\n",
    "train_label = mbti_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#전체 data 중 train의 비율\n",
    "train_ratio = 0.8\n",
    "\n",
    "train_idx = np.random.choice(len(train_data), int(len(train_data) * train_ratio), replace=False)\n",
    "test_idx = np.array(list(set(range(len(train_data))) - set(train_idx)))\n",
    "\n",
    "test_data = train_data[test_idx]\n",
    "test_label = train_label[test_idx]\n",
    "\n",
    "train_data = train_data[train_idx]\n",
    "train_label = train_label[train_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining model\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MBTI_Dataset(Dataset):\n",
    "    def __init__(self, train_label, train_data):\n",
    "        self.train_label = train_label\n",
    "        self.train_data = train_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_label)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        mbti = self.train_label[idx]\n",
    "        photo = self.train_data[idx]\n",
    "\n",
    "        return mbti, photo\n",
    "\n",
    "# parameter 값은 이것을 변경해주세요\n",
    "in_ch1 = 1\n",
    "out_ch1 = 16\n",
    "ker1 = 4\n",
    "stride1 = 1\n",
    "pad1 = 0\n",
    "\n",
    "out_ch2 = 16\n",
    "ker2 = 3\n",
    "stride2 = 1\n",
    "pad2 = 0\n",
    "\n",
    "out_ch3 = 32\n",
    "ker3 = 2\n",
    "stride3 = 1\n",
    "pad3 = 0\n",
    "\n",
    "out_ch4 = 64\n",
    "ker4 = 2\n",
    "stride4 = 1\n",
    "pad4 = 0\n",
    "\n",
    "out_ch5 = 128\n",
    "ker5 = 2\n",
    "stride5 = 1\n",
    "pad5 = 0\n",
    "\n",
    "\n",
    "pool_size1 = 3\n",
    "pool_size2 = 2\n",
    "pool_size3 = 2\n",
    "pool_size4 = 2\n",
    "pool_size5 = 2\n",
    "\n",
    "out_feat1 = 120\n",
    "out_feat2 = 84\n",
    "out_feat3 = 1\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super(Net, self).__init__()\n",
    "        input_height, input_width = input_shape\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels = in_ch1, out_channels = out_ch1, kernel_size = ker1, stride = stride1, padding = pad1)\n",
    "        self.pool1 = nn.MaxPool2d(pool_size1, pool_size1)\n",
    "\n",
    "        output1_height, output1_width = (input_height - ker1 + 2 * pad1) / stride1 + 1, (input_width - ker1 + 2 * pad1) / stride1 + 1\n",
    "        output1_height, output1_width = int(output1_height / pool_size1), int(output1_width / pool_size1)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_ch1, out_ch2, ker2, stride2, pad2)\n",
    "        self.pool2 = nn.MaxPool2d(pool_size2, pool_size2)\n",
    "\n",
    "        output2_height, output2_width = (output1_height - ker2 + 2 * pad2) / stride2 + 1, (output1_width - ker2 + 2 * pad2) / stride2 + 1\n",
    "        output2_height, output2_width = int(output2_height / pool_size2), int(output2_width / pool_size2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(out_ch2, out_ch3, ker3, stride3, pad3)\n",
    "        self.pool3 = nn.MaxPool2d(pool_size3, pool_size3)\n",
    "\n",
    "        output3_height, output3_width = (output2_height - ker3 + 2 * pad3) / stride3 + 1, (output2_width - ker3 + 2 * pad3) / stride3 + 1\n",
    "        output3_height, output3_width = int(output3_height / pool_size3), int(output3_width / pool_size3)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(out_ch3, out_ch4, ker4, stride4, pad4)\n",
    "        self.pool4 = nn.MaxPool2d(pool_size3, pool_size3)\n",
    "        \n",
    "        output4_height, output4_width = (output3_height - ker4 + 2 * pad4) / stride4 + 1, (output3_width - ker4 + 2 * pad4) / stride4 + 1\n",
    "        output4_height, output4_width = int(output4_height / pool_size3), int(output4_width / pool_size3)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(out_ch4, out_ch5, ker5, stride5, pad5)\n",
    "        self.pool5 = nn.MaxPool2d(pool_size5, pool_size5)\n",
    "\n",
    "        output5_height, output5_width = (output4_height - ker5 + 2 * pad5) / stride5 + 1, (output4_width - ker5 + 2 * pad5) / stride5 + 1\n",
    "        output5_height, output5_width = int(output5_height / pool_size5), int(output5_width / pool_size5)\n",
    "\n",
    "        self.fc1 = nn.Linear(out_ch3 * output3_height * output3_width, out_feat1)\n",
    "        self.fc2 = nn.Linear(out_feat1, out_feat2)\n",
    "        self.fc3 = nn.Linear(out_feat2, out_feat3)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = self.pool3(F.relu(self.conv3(x)))\n",
    "        x = self.pool4(F.relu(self.conv4(x)))\n",
    "        # x = self.pool5(F.relu(self.conv5(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        # 이 부분은 변경하셔도 괜찮아요. relu로 할지 sigmoid로 할지\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "class cnn_model():\n",
    "    def __init__(self, model, lr=0.01, epochs=100, momentum = 0.6):\n",
    "        self.model = model\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.momentum = momentum\n",
    "        self.criterion = nn.BCEWithLogitsLoss()\n",
    "        self.optimizer = torch.optim.SGD(self.model.parameters(), lr=self.lr, momentum = self.momentum)\n",
    "    \n",
    "    def fit(self, X_train, y_train):        \n",
    "        self.trainloader = DataLoader(MBTI_Dataset(X_train, y_train), batch_size=64, shuffle=False)\n",
    "        \n",
    "        self.model.train()\n",
    "        for epoch in range(self.epochs):\n",
    "            for i, data in enumerate(self.trainloader):\n",
    "                inputs, labels = data\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(inputs)\n",
    "                labels.unsqueeze_(1)\n",
    "                loss = self.criterion(outputs, labels.float())\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "    \n",
    "    def predict(self, x):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred = self.model(x.unsqueeze(0))\n",
    "        return y_pred\n",
    "\n",
    "    def get_params(self, deep=True):\n",
    "        return {'lr': self.lr, 'epochs': self.epochs, 'momentum': self.momentum}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net((train_data[0].shape[1], train_data[0].shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def cross_val_score(model, train_data, label, cv=2):\n",
    "    k = cv\n",
    "    kf = KFold(n_splits=k, random_state=42, shuffle=True)\n",
    "\n",
    "    acc_score = []\n",
    "    auc_score = []\n",
    "    \n",
    "    for train_index , test_index in kf.split(train_data):\n",
    "        X_train , X_test = train_data[train_index],train_data[test_index]\n",
    "        y_train , y_test = label[train_index] , label[test_index]\n",
    "        \n",
    "        if(np.unique(y_test).shape[0] == 1):\n",
    "            print('only one class')\n",
    "            continue\n",
    "\n",
    "        model.fit(X_train,y_train)\n",
    "\n",
    "        pred_values = []\n",
    "\n",
    "        for i in range(len(X_test)):\n",
    "            pred = model.predict(X_test[i])\n",
    "            pred_values.append(pred.item())\n",
    "\n",
    "        auc = roc_auc_score(y_test, pred_values)\n",
    "        auc_score.append(auc)\n",
    "        \n",
    "    avg_acc_score = sum(acc_score)/k\n",
    "    avg_auc_score = sum(auc_score)/k\n",
    "    \n",
    "    return avg_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make tupes of (lr, momentum, epochs) randomly\n",
    "# random cv를 몇번 돌릴 것인지...\n",
    "random_cv_num = 5\n",
    "\n",
    "# parameter 값이 이 범위 내에서 나옵니다\n",
    "lrs = np.linspace(0.01, 0.1, 30)\n",
    "momentums = np.linspace(0.1, 0.9, 20)\n",
    "epochss = np.linspace(100, 400, 5, dtype=int)\n",
    "\n",
    "params = [(lr, momentum, epochs) for lr in lrs for momentum in momentums for epochs in epochss]\n",
    "np.random.shuffle(params)\n",
    "params = params[:random_cv_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (64x64 and 512x120)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [50], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m cv_params \u001b[39m=\u001b[39m []\n\u001b[1;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m models:\n\u001b[0;32m----> 7\u001b[0m     cv_scores\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39mmean(cross_val_score(model, train_data, train_label, cv\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)))\n\u001b[1;32m      8\u001b[0m     cv_params\u001b[39m.\u001b[39mappend(model\u001b[39m.\u001b[39mget_params())\n\u001b[1;32m     10\u001b[0m cv_scores \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(cv_scores)\n",
      "Cell \u001b[0;32mIn [48], line 20\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(model, train_data, label, cv)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39monly one class\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     18\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train,y_train)\n\u001b[1;32m     22\u001b[0m pred_values \u001b[39m=\u001b[39m []\n\u001b[1;32m     24\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(X_test)):\n",
      "Cell \u001b[0;32mIn [46], line 133\u001b[0m, in \u001b[0;36mcnn_model.fit\u001b[0;34m(self, X_train, y_train)\u001b[0m\n\u001b[1;32m    131\u001b[0m inputs, labels \u001b[39m=\u001b[39m data\n\u001b[1;32m    132\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m--> 133\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(inputs)\n\u001b[1;32m    134\u001b[0m labels\u001b[39m.\u001b[39munsqueeze_(\u001b[39m1\u001b[39m)\n\u001b[1;32m    135\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion(outputs, labels\u001b[39m.\u001b[39mfloat())\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [46], line 111\u001b[0m, in \u001b[0;36mNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    108\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mflatten(x, \u001b[39m1\u001b[39m)\n\u001b[1;32m    110\u001b[0m \u001b[39m# 이 부분은 변경하셔도 괜찮아요. relu로 할지 sigmoid로 할지\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msigmoid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc1(x))\n\u001b[1;32m    112\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc2(x))\n\u001b[1;32m    113\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msigmoid(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc3(x))\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x64 and 512x120)"
     ]
    }
   ],
   "source": [
    "models = [cnn_model(net, lr, epochs, momentum) for lr, momentum, epochs in params]\n",
    "\n",
    "cv_scores = []\n",
    "cv_params = []\n",
    "\n",
    "for model in models:\n",
    "    cv_scores.append(np.mean(cross_val_score(model, train_data, train_label, cv=3)))\n",
    "    cv_params.append(model.get_params())\n",
    "\n",
    "cv_scores = np.array(cv_scores)\n",
    "cv_params = np.array(cv_params)\n",
    "\n",
    "best_params = cv_params[np.argmax(cv_scores)]\n",
    "best_score = np.max(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best lr:  0.0813793103448276 Best momentum:  0.1842105263157895 Best epochs:  250\n"
     ]
    }
   ],
   "source": [
    "print('Best lr: ', best_params['lr'], 'Best momentum: ', best_params['momentum'], 'Best epochs: ', best_params['epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#그냥 노가다로 스윗 스팟을 찾고 싶다면...\n",
    "best_params = {'lr': 0.034827586206896556, 'momentum': 0.8157894736842105, 'epochs': 175}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold:  0.3081999999998559\n",
      "Best score for train set:  0.5729665071770335\n",
      "0.5789473684210527\n"
     ]
    }
   ],
   "source": [
    "#import roc curve\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "#calculate test accuracy score\n",
    "#model = cnn_model(model = net, lr = best_params['lr'], momentum = best_params['momentum'], epochs = best_params['epochs'])\n",
    "model = cnn_model(model = net, lr = 0.001, momentum = 0.2, epochs = 50)\n",
    "model.fit(train_data, train_label)\n",
    "\n",
    "train_pred_values = []\n",
    "\n",
    "for i in range(len(train_data)):\n",
    "    pred = model.predict(train_data[i])\n",
    "    train_pred_values.append(pred.item())\n",
    "\n",
    "#calculate mean and variance of train_pred\n",
    "train_pred_values = np.array(train_pred_values)\n",
    "train_pred_mean = np.mean(train_pred_values)\n",
    "train_pred_var = np.var(train_pred_values)\n",
    "\n",
    "#normalize train_pred_values\n",
    "train_pred_values = (train_pred_values - train_pred_mean) / np.sqrt(train_pred_var)\n",
    "\n",
    "# draw the histogram of train_pred_values\n",
    "plt.hist(train_pred_values, bins=100)\n",
    "plt.show()\n",
    "\n",
    "best_threshold = 0\n",
    "best_score = 0\n",
    "\n",
    "for threshold in np.arange(-1, 1, 0.0001):\n",
    "    y_pred = np.array(train_pred_values) > threshold\n",
    "    score = accuracy_score(train_label, y_pred)\n",
    "    if score > best_score:\n",
    "        best_threshold = threshold\n",
    "        best_score = score\n",
    "\n",
    "print('Best threshold: ', best_threshold)\n",
    "print('Best score for train set: ', best_score)\n",
    "\n",
    "pred_values = []\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    pred = model.predict(test_data[i])\n",
    "    pred_values.append(pred.item())\n",
    "\n",
    "#quantize predictions\n",
    "pred_values = np.array(pred_values)\n",
    "\n",
    "#normalize pred_values\n",
    "pred_values = (pred_values - train_pred_mean) / np.sqrt(train_pred_var)\n",
    "\n",
    "pred_values[pred_values >= best_threshold] = 1\n",
    "pred_values[pred_values < best_threshold] = 0\n",
    "\n",
    "#calculate accuracy score\n",
    "guess1 = accuracy_score(test_label, pred_values)\n",
    "print(guess1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5311004784688995\n"
     ]
    }
   ],
   "source": [
    "# random guess\n",
    "\n",
    "pred_values = []\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    pred = 0\n",
    "    pred_values.append(pred)\n",
    "\n",
    "#quantize predictions\n",
    "pred_values = np.array(pred_values)\n",
    "\n",
    "#calculate accuracy score\n",
    "guess2 = accuracy_score(test_label, pred_values)\n",
    "print(guess2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model is  4.784688995215314 % better than random guess\n"
     ]
    }
   ],
   "source": [
    "print('the model is ', (guess1-guess2)*100, '% better than random guess')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best model in pickle\n",
    "import pickle\n",
    "\n",
    "with open('model1.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc auc score:  0.5068870523415977\n"
     ]
    }
   ],
   "source": [
    "# calculate roc curve\n",
    "fpr, tpr, thresholds = roc_curve(test_label, pred_values)\n",
    "\n",
    "# calculate the best quantize threshold using roc curve\n",
    "best_threshold = 0\n",
    "\n",
    "for i in range(len(fpr)):\n",
    "    if fpr[i] >= 0.1 and fpr[i] <= 0.2:\n",
    "        best_threshold = thresholds[i]\n",
    "\n",
    "pred_values = []\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    pred = model.predict(test_data[i])\n",
    "    pred_values.append(pred.item())\n",
    "\n",
    "#quantize predictions\n",
    "pred_values = np.array(pred_values)\n",
    "\n",
    "#normalize pred_values\n",
    "pred_values = (pred_values - train_pred_mean) / np.sqrt(train_pred_var)\n",
    "\n",
    "guess3 = roc_auc_score(test_label, pred_values)\n",
    "\n",
    "pred_values[pred_values >= best_threshold] = 1\n",
    "pred_values[pred_values < best_threshold] = 0\n",
    "\n",
    "#calculate roc score\n",
    "print('roc auc score: ', guess3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eda7e54fe21129b67f77862937907ee926f057597a3e2fa1e18ac955e40912b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
