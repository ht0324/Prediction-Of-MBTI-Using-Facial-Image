{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"-rRfx6MmppaW"},"outputs":[],"source":["import torch\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import torchvision.transforms as transforms\n","\n","transform = transforms.ToTensor()"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"wB_g59Flppam"},"outputs":[],"source":["image = Image.open('crop/' + 'estj0_face.jpg')"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"EN408M4tppaq","outputId":"b72e3baf-37ff-4d07-f1bc-79480cd7b602"},"outputs":[{"data":{"text/plain":["0    istj\n","1    istj\n","2    istj\n","3    istj\n","4    istj\n","Name: MBTI, dtype: object"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["mbti_df = pd.read_csv('crop/all.csv')\n","\n","photo_df = pd.DataFrame(columns=['photo'], dtype= 'object')\n","\n","# put the photo data into a dataframe\n","for i in range(len(mbti_df)):\n","    image = transform(Image.open('crop/' + mbti_df['file_name'][i]))\n","    photo_df.loc[i] = [image]\n","\n","mbti_df = mbti_df['MBTI']\n","\n","mbti_df.head()"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"rZsL-1RAppav","outputId":"7977069e-c000-46fa-9a74-e8de120bbb3b"},"outputs":[{"data":{"text/plain":["torch.Size([1, 64, 64])"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["photo_df.iloc[0][0].shape"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"-B5TapYyppax","outputId":"4f9a895d-6198-41bc-ddd1-e7c01a4a4549"},"outputs":[{"data":{"text/plain":["0    1\n","1    1\n","2    1\n","3    1\n","4    1\n","Name: MBTI, dtype: int64"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["alphabet = ['e', 'i']\n","\n","# if mbti_df['MBTI'] includes alphabet[0], then mbti_df['MBTI'] = 0, else 1\n","mbti_df = mbti_df.apply(lambda x: 0 if alphabet[0] in x else 1)\n","\n","mbti_df.head()"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"iHquVLGoppa0"},"outputs":[],"source":["# train_data includes the element of 2-dim tensor\n","train_data = photo_df['photo'].values\n","train_label = mbti_df.values"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"diCvsZvlppa2"},"outputs":[],"source":["#전체 data 중 train의 비율\n","train_ratio = 0.6\n","\n","train_idx = np.random.choice(len(train_data), int(len(train_data) * train_ratio), replace=False)\n","test_idx = np.array(list(set(range(len(train_data))) - set(train_idx)))\n","\n","test_data = train_data[test_idx]\n","test_label = train_label[test_idx]\n","\n","train_data = train_data[train_idx]\n","train_label = train_label[train_idx]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XE9-Xs70ppa7"},"outputs":[],"source":["#defining model\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from sklearn.preprocessing import StandardScaler\n","from torch.utils.data import Dataset, DataLoader\n","\n","class MBTI_Dataset(Dataset):\n","    def __init__(self, train_label, train_data):\n","        self.train_label = train_label\n","        self.train_data = train_data\n","\n","    def __len__(self):\n","        return len(self.train_label)\n","\n","    def __getitem__(self, idx):\n","        if torch.is_tensor(idx):\n","            idx = idx.tolist()\n","\n","        mbti = self.train_label[idx]\n","        photo = self.train_data[idx]\n","\n","        return mbti, photo\n","\n","# parameter 값은 이것을 변경해주세요\n","in_ch1 = 1\n","out_ch1 = 6\n","ker1 = 5\n","stride1 = 1\n","pad1 = 0\n","\n","out_ch2 = 16\n","ker2 = 5\n","stride2 = 1\n","pad2 = 0\n","\n","out_ch3 = 32\n","ker3 = 5\n","stride3 = 1\n","pad3 = 0\n","\n","pool_size1 = 2\n","pool_size2 = 2\n","pool_size3 = 1\n","\n","out_feat1 = 120\n","out_feat2 = 84\n","out_feat3 = 1\n","\n","\n","class Net(nn.Module):\n","    def __init__(self, input_shape):\n","        super(Net, self).__init__()\n","        input_height, input_width = input_shape\n","\n","        self.conv1 = nn.Conv2d(in_channels = in_ch1, out_channels = out_ch1, kernel_size = ker1, stride = stride1, padding = pad1)\n","        self.pool1 = nn.MaxPool2d(pool_size1, pool_size1)\n","\n","        output1_height, output1_width = (input_height - ker1 + 2 * pad1) / stride1 + 1, (input_width - ker1 + 2 * pad1) / stride1 + 1\n","        output1_height, output1_width = int(output1_height / pool_size1), int(output1_width / pool_size1)\n","\n","        self.conv2 = nn.Conv2d(out_ch1, out_ch2, ker2, stride2, pad2)\n","        self.pool2 = nn.MaxPool2d(pool_size2, pool_size2)\n","\n","        output2_height, output2_width = (output1_height - ker2 + 2 * pad2) / stride2 + 1, (output1_width - ker2 + 2 * pad2) / stride2 + 1\n","        output2_height, output2_width = int(output2_height / pool_size2), int(output2_width / pool_size2)\n","\n","        self.conv3 = nn.Conv2d(out_ch2, out_ch3, ker3, stride3, pad3)\n","        self.pool3 = nn.MaxPool2d(pool_size3, pool_size3)\n","\n","        output3_height, output3_width = (output2_height - ker3 + 2 * pad3) / stride3 + 1, (output2_width - ker3 + 2 * pad3) / stride3 + 1\n","        output3_height, output3_width = int(output3_height / pool_size3), int(output3_width / pool_size3)\n","\n","        self.fc1 = nn.Linear(out_ch3 * output3_height * output3_width, out_feat1)\n","        self.fc2 = nn.Linear(out_feat1, out_feat2)\n","        self.fc3 = nn.Linear(out_feat2, out_feat3)\n","\n","    \n","    def forward(self, x):\n","        x = self.pool1(F.relu(self.conv1(x)))\n","        x = self.pool2(F.relu(self.conv2(x)))\n","        x = self.pool3(F.relu(self.conv3(x)))\n","        x = torch.flatten(x, 1)\n","\n","        # 이 부분은 변경하셔도 괜찮아요. relu로 할지 sigmoid로 할지\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = torch.sigmoid(self.fc3(x))\n","        return x\n","\n","class cnn_model():\n","    def __init__(self, model, lr=0.01, epochs=100, momentum = 0.6):\n","        self.model = model\n","        self.lr = lr\n","        self.epochs = epochs\n","        self.momentum = momentum\n","        self.criterion = nn.BCEWithLogitsLoss()\n","        self.optimizer = torch.optim.SGD(self.model.parameters(), lr=self.lr, momentum = self.momentum)\n","    \n","    def fit(self, X_train, y_train):        \n","        self.trainloader = DataLoader(MBTI_Dataset(X_train, y_train), batch_size=64, shuffle=False)\n","        \n","        self.model.train()\n","        for epoch in range(self.epochs):\n","            for i, data in enumerate(self.trainloader):\n","                inputs, labels = data\n","                self.optimizer.zero_grad()\n","                outputs = self.model(inputs)\n","                labels.unsqueeze_(1)\n","                loss = self.criterion(outputs, labels.float())\n","                loss.backward()\n","                self.optimizer.step()\n","    \n","    def predict(self, x):\n","        self.model.eval()\n","        with torch.no_grad():\n","            y_pred = self.model(x.unsqueeze(0))\n","        return y_pred\n","\n","    def get_params(self, deep=True):\n","        return {'lr': self.lr, 'epochs': self.epochs, 'momentum': self.momentum}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9I7v4SBZppbD"},"outputs":[],"source":["net = Net((train_data[0].shape[1], train_data[0].shape[2]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h5LD5VsuppbI"},"outputs":[],"source":["from sklearn.model_selection import KFold\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import accuracy_score\n","\n","def cross_val_score(model, train_data, label, cv=2):\n","    k = cv\n","    kf = KFold(n_splits=k, random_state=42, shuffle=True)\n","\n","    acc_score = []\n","    auc_score = []\n","    \n","    for train_index , test_index in kf.split(train_data):\n","        X_train , X_test = train_data[train_index],train_data[test_index]\n","        y_train , y_test = label[train_index] , label[test_index]\n","        \n","        if(np.unique(y_test).shape[0] == 1):\n","            print('only one class')\n","            continue\n","\n","        model.fit(X_train,y_train)\n","\n","        pred_values = []\n","\n","        for i in range(len(X_test)):\n","            pred = model.predict(X_test[i])\n","            pred_values.append(pred.item())\n","\n","        auc = roc_auc_score(y_test, pred_values)\n","        auc_score.append(auc)\n","        \n","    avg_acc_score = sum(acc_score)/k\n","    avg_auc_score = sum(auc_score)/k\n","    \n","    return avg_acc_score"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-Z8oEXEAppbK"},"outputs":[],"source":["# make tupes of (lr, momentum, epochs) randomly\n","# random cv를 몇번 돌릴 것인지...\n","random_cv_num = 25\n","\n","# parameter 값이 이 범위 내에서 나옵니다\n","lrs = np.linspace(0.01, 0.1, 30)\n","momentums = np.linspace(0.1, 0.9, 20)\n","epochss = np.linspace(100, 400, 5, dtype=int)\n","\n","params = [(lr, momentum, epochs) for lr in lrs for momentum in momentums for epochs in epochss]\n","np.random.shuffle(params)\n","params = params[:random_cv_num]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-89GwlX4ppbM","outputId":"49255ae1-a407-4cc5-eee5-e387f70e1996"},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn [611], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m cv_params \u001b[39m=\u001b[39m []\n\u001b[0;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m models:\n\u001b[1;32m----> 7\u001b[0m     cv_scores\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39mmean(cross_val_score(model, train_data, train_label, cv\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)))\n\u001b[0;32m      8\u001b[0m     cv_params\u001b[39m.\u001b[39mappend(model\u001b[39m.\u001b[39mget_params())\n\u001b[0;32m     10\u001b[0m cv_scores \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(cv_scores)\n","Cell \u001b[1;32mIn [609], line 20\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(model, train_data, label, cv)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39monly one class\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     18\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train,y_train)\n\u001b[0;32m     22\u001b[0m pred_values \u001b[39m=\u001b[39m []\n\u001b[0;32m     24\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(X_test)):\n","Cell \u001b[1;32mIn [607], line 113\u001b[0m, in \u001b[0;36mcnn_model.fit\u001b[1;34m(self, X_train, y_train)\u001b[0m\n\u001b[0;32m    111\u001b[0m labels\u001b[39m.\u001b[39munsqueeze_(\u001b[39m1\u001b[39m)\n\u001b[0;32m    112\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion(outputs, labels\u001b[39m.\u001b[39mfloat())\n\u001b[1;32m--> 113\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m    114\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep()\n","File \u001b[1;32mc:\\Users\\opush\\anaconda3\\envs\\PyTorch\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n","File \u001b[1;32mc:\\Users\\opush\\anaconda3\\envs\\PyTorch\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["models = [cnn_model(net, lr, epochs, momentum) for lr, momentum, epochs in params]\n","\n","cv_scores = []\n","cv_params = []\n","\n","for model in models:\n","    cv_scores.append(np.mean(cross_val_score(model, train_data, train_label, cv=3)))\n","    cv_params.append(model.get_params())\n","\n","cv_scores = np.array(cv_scores)\n","cv_params = np.array(cv_params)\n","\n","best_params = cv_params[np.argmax(cv_scores)]\n","best_score = np.max(cv_scores)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C9ubtrecppbP","outputId":"6c6e01b5-a177-480f-a83a-77f6ee34983a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Best lr:  0.050344827586206904 Best momentum:  0.6052631578947368 Best epochs:  175\n"]}],"source":["print('Best lr: ', best_params['lr'], 'Best momentum: ', best_params['momentum'], 'Best epochs: ', best_params['epochs'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2CZA6e7_ppbQ"},"outputs":[],"source":["#그냥 노가다로 스윗 스팟을 찾고 싶다면...\n","#best_params = {'lr': 0.01, 'momentum': 0.1, 'epochs': 100}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6q2aYKP3ppbS","outputId":"a1214586-69b2-4cf6-be90-1e78d66faa29"},"outputs":[{"name":"stdout","output_type":"stream","text":["Best threshold:  0.37\n","Best score for train set:  0.569377990430622\n","0.5311004784688995\n"]}],"source":["#import roc curve\n","from sklearn.metrics import roc_curve\n","\n","#calculate test accuracy score\n","model = cnn_model(model = net, lr = best_params['lr'], momentum = best_params['momentum'], epochs = best_params['epochs'])\n","model.fit(train_data, train_label)\n","\n","train_pred_values = []\n","\n","for i in range(len(train_data)):\n","    pred = model.predict(train_data[i])\n","    train_pred_values.append(pred.item())\n","\n","\n","best_threshold = 0\n","best_score = 0\n","\n","for threshold in np.arange(0, 1, 0.0005):\n","    y_pred = np.array(train_pred_values) > threshold\n","    score = accuracy_score(train_label, y_pred)\n","    if score > best_score:\n","        best_threshold = threshold\n","        best_score = score\n","\n","print('Best threshold: ', best_threshold)\n","print('Best score for train set: ', best_score)\n","\n","pred_values = []\n","\n","for i in range(len(test_data)):\n","    pred = model.predict(test_data[i])\n","    pred_values.append(pred.item())\n","\n","#quantize predictions\n","pred_values = np.array(pred_values)\n","pred_values[pred_values >= best_threshold] = 1\n","pred_values[pred_values < best_threshold] = 0\n","\n","#calculate accuracy score\n","guess1 = accuracy_score(test_label, pred_values)\n","print(guess1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-oVYsV0JppbU","outputId":"d6070ff7-ffa2-47bb-cc51-d16a4e3adaf5"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.5454545454545454\n"]}],"source":["# random guess\n","\n","pred_values = []\n","\n","for i in range(len(test_data)):\n","    pred = 1\n","    pred_values.append(pred)\n","\n","#quantize predictions\n","pred_values = np.array(pred_values)\n","\n","#calculate accuracy score\n","guess2 = accuracy_score(test_label, pred_values)\n","print(guess2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V3J3K9TvppbV","outputId":"f3747d27-d607-474c-8ed4-e44b03754d0e"},"outputs":[{"name":"stdout","output_type":"stream","text":["the model is  -1.4354066985645897  % better than random guess\n"]}],"source":["print('the model is ', (guess1-guess2)*100, '% better than random guess')"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.10.8 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"eda7e54fe21129b67f77862937907ee926f057597a3e2fa1e18ac955e40912b3"}}},"nbformat":4,"nbformat_minor":0}
